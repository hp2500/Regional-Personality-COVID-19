---
title: "COVID19"
author: "Heinrich Peters"
date: "4/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# MAC
 knitr::opts_knit$set(root.dir = '/Users/hp2500/Google Drive/STUDY/Columbia/Research/Corona/Data')
 
 library(tidyverse)
 library(lmerTest)

```

# Import Data
```{r}
# read data
df <- read_csv('mp_features.csv')
df %>% head()

df_pers <- read_csv('gps_study_questionnares.csv')
df_pers %>% head()


df_home <- read_csv('home2.csv')
df_home %>% head()

```

# Explore and Clean GPS Data

## Fix format 
```{r}

# drop pandas index
df = df %>% select(-X1) 

# filter to march 2020
df <- df %>% filter(date > '2020-02-29')

# cast uid as factor
df <- df %>% mutate(uid = as.factor(uid))

df
```


## Select relevant variables 
```{r}

# picked raw entropy, too many missing in ent_value
df <- df %>% select(uid, date, raw_ent_value, num_cluster_value,
                    per_at_home, transition_time_value, dis_value,
                    convex_hull_value, num_gps_records)
```


## Check data density
```{r}

colSums(is.na(df))

df$num_gps_records %>% 
  hist(main='GPS records per day')

df %>% group_by(uid) %>% 
  summarise(num_gps_records = sum(num_gps_records)) %>% 
  .$num_gps_records %>% 
  hist(main='GPS records per person')

df %>% group_by(uid) %>% 
  summarise(days = n()) %>% 
  .$days %>% 
  hist(main = 'Days per person')

```

## Drop days and people with little data
```{r}
df_clean <- df %>%
  drop_na() %>%
  filter(num_gps_records > 20) %>% 
  group_by(uid) %>%
  filter(n() > 5) %>%
  ungroup()

df_clean
```

## Double check data density
```{r}
df_clean$num_gps_records %>% 
  hist(main='GPS records per day')

df_clean %>% group_by(uid) %>% 
  summarise(num_gps_records = sum(num_gps_records)) %>% 
  .$num_gps_records %>%
  hist(main='GPS records per person')

df_clean %>% group_by(uid) %>% 
  summarise(days = n()) %>% 
  .$days %>% 
  hist(main = 'Days per person')
```


## Fix time 
```{r}

date_sequence <- seq.Date(min(as.Date(df$date)),
                     max(as.Date(df$date)), 1)

df_dates = data_frame(date_sequence, 1:length(date_sequence)) 
names(df_dates) <- c('date', 'day')

df_clean = df_clean %>% 
  merge(df_dates, by='date') %>% 
  arrange(uid) %>%
  as_tibble()

df_clean

```


# Calculate social distancing index
```{r}

df_scaled <- df_clean %>% 
  mutate_at(vars(-uid, -date, -num_gps_records, -day), scale) %>%
  mutate(per_at_home= -per_at_home) %>%
  rowwise() %>%
  mutate(SDI = - mean(c(raw_ent_value:convex_hull_value)))

df_scaled

```



# Explore and clean personality data

## Drop irrelevant data
```{r}

df_pers_clean <- df_pers %>% select(identity_id, anxious_calm, critical_sympathetic, 
                   dependable_disorganized, extroverted_reserved, 
                   open_conventional) %>%
  rename(uid=identity_id, 
         n_pers=anxious_calm,
         a_pers=critical_sympathetic,
         c_pers=dependable_disorganized,
         e_pers=extroverted_reserved,
         o_pers=open_conventional) %>%
  mutate(uid=as.factor(uid))


```

## Recode personality scores
```{r}
df_pers_clean <- df_pers_clean %>% 
  mutate(e_pers = 6-e_pers,
         c_pers = 6-c_pers,
         n_pers = 6-n_pers,
         o_pers = 6-o_pers)

```



## Check distributions 
```{r}
df_pers_clean %>% select(-uid) %>% map(hist, breaks=0:6) %>% invisible()

```

# Explore and clean home state data
```{r}

df_home_clean <- df_home %>% 
  separate(address, into = c('city', 'state', NULL), sep=",") %>% 
  mutate(state = str_extract(state, '[A-Z]{2}')) %>%
  rename(uid = identity_id) %>%
  select(uid, state) %>% 
  filter(state %in% state.abb)


```

# Merge data 
```{r}
df_merged <- plyr::join_all(list(df_scaled, df_pers_clean, df_home_clean), by = 'uid', type = 'inner') %>%
  as_tibble()

df_merged 
```

# Analysis 
## Check correlations
```{r}
df_merged %>% select(-uid, -date, -state) %>% cor()

```

# MLMs

## Prepare data
```{r}
df_merged <- df_merged %>% 
  select(uid, day, o_pers, c_pers, e_pers, a_pers, n_pers, SDI) %>% 
  mutate_at(vars(-uid, -day, -SDI), scale)
```


## Opennness 
```{r, warning = FALSE}

# baseline
a_baseline <- lmer(SDI ~ (1 | uid), data = df_merged, REML = F)
summary(a_baseline)

# random intercept fixed slope
a_random_intercept <- lmer(SDI ~ day + a_pers + (1 | uid), data = df_merged, REML = F)
summary(a_random_intercept)

# random intercept random slope
a_random_slope <- lmer(SDI ~ day + a_pers + (day | uid), data = df_merged, REML = F)
summary(a_random_slope)

# cross level interaction
a_interaction <- lmer(SDI ~ day*a_pers + (day | uid), data = df_merged, REML = F)
summary(a_interaction)

```

